<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Mathematically, Principal Component Analysis</title>
  <meta name="description" content="Things that I have done, learnt and thought about.
" />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <link rel="canonical" href="http://www.rajathkumar.com/pca/">

  <link rel="shortcut icon" href="/assets/images/favicon.ico">
<!--  <link rel="stylesheet" href=""> -->
  <link rel="stylesheet" href="http://brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
  <link href='http://fonts.googleapis.com/css?family=Cookie' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/print.css" />
  <script type="text/javascript"
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js">
</script>
</head>

  <body itemscope itemtype="http://schema.org/Article">
    <!-- header start -->

<a href="http://www.rajathkumar.com" class="logo-readium"><span class="fa-stack fa-lg"><i class="fa fa-square-o fa-stack-2x" style="color:black"></i><i class="fa fa-home fa-stack-1x" style="color:black"></i></span></a>

<!-- header end -->

    <main class="content" role="main">
      <article class="post">
        
        <div class="noarticleimage">
          <div class="post-meta">
            <h1 class="post-title">Mathematically, Principal Component Analysis</h1>
            <div class="cf post-meta-text">
              <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
              <h4 class="author-name" itemprop="author" itemscope itemtype="http://schema.org/Person"></h4>
              on
              <time datetime="2015-11-19T01:51:21+05:30">19 Nov 2015</time>
              <!-- , tagged on <span class="post-tag-">, <a href="/tag/"></a></span> -->
            </div>
          </div>
        </div>
        <br>
        <br>
        <br>
        
        <section class="post-content">
          <div class="post-reading">
            <span class="post-reading-time"></span> read
          </div>
          <a name="topofpage"></a>
          <h4 id="prologue">Prologue</h4>

<p>In this post, Principal Component Analysis will be broken down into mathematical bits one can easily understand. For a better insight a quick walkthrough of important mathematical concepts that you might have studied but haven&#39;t used in the real sense is done where necessary. The entire concept is explained by using an example, Hope this approach will help in complete understanding of the topic.</p>

<h4 id="principal-component-analysis">Principal Component Analysis</h4>

<p>It is the oldest and the most widely used statistical multivariate technique which finds a pattern in the data under consideration. PCA can be further extended towards dimensionality reduction by extracting important features which are necessary to the given problem statement and ignoring the ones which aren&#39;t. It find&#39;s its application in face recognition, image compression, dimensionality reduction etc.</p>

<p>Let us get into the nitty gritty, First, I will explain by taking an example and applying PCA to a simple one dimensional dataset. Further will take two dimensions and extend them to multi dimensions.</p>

<p>Consider a data set that you would like to study. As an example let us take some random <strong>one dimensional</strong> dataset <em>X</em></p>
<div class="highlight"><pre><code class="language-text" data-lang="text">X = { 5,2,3,9,1,4 }
</code></pre></div>
<p>Now calculating the <strong>mean</strong> of <em>X</em> with <em>n</em> number of data by using the formula</p>

<p>$${\bar{X} = \frac{ \sum_ {i=1}^n X_i}{n}}$$</p>

<p>Thus, the mean, \(\bar{X}\) will now be equal to <em>4</em>. Mean as everybody knows it gives the center point of the dataset.</p>

<p>Now consider another dataset </p>
<div class="highlight"><pre><code class="language-text" data-lang="text">Y = { 5,3,2,7,2,5 }
</code></pre></div>
<p>Notice the mean, \(\bar{Y}\) of this dataset is also <em>4</em>. So now how do you know how these two data are different? Or how they variy?</p>

<p><strong>Standard Deviation</strong>. Wikipedia defines it as <em>&quot;A measure that is used to quantify the amount of variation or dispersion of a set of data values&quot;</em> which simply means it gives a picture about how the data varies with respect to the mean. For the <em>X</em> dataset standard deviation is given by the formula</p>

<p>$$SD = \sqrt{\frac{ \sum_ {i=1}^n {(X_i-\bar{X})^2}}{(n-1)}}$$</p>

<p>Took me sometime to understand as to why <code>(n-1)</code> is used. Wikipedia has the <a href="https://en.wikipedia.org/wiki/Standard_deviation">perfect explanation</a>. As of now, understand it is Bessel&#39;s correction and applying it would give a better answer.</p>

<p>Now <strong>variance</strong> is nothing but the square of standard deviation.</p>

<p>$$var = SD^2$$</p>

<p>or</p>

<p>$$var={\frac{ \sum_ {i=1}^n {(X_i-\bar{X})^2}}{(n-1)}}$$</p>

<p>The variance of <em>X</em> is 8 and that of <em>Y</em> is 4. Which tells us that the data of <em>X</em> is more varied or spread across than the data of <em>Y</em></p>

<p>Now let us consider two dimensional data, <code>(X,Y)</code> say</p>

<table><thead>
<tr>
<th>X</th>
<th style="text-align: center"><em>2</em></th>
<th style="text-align: right"><em>3</em></th>
<th style="text-align: right"><em>5</em></th>
<th style="text-align: right"><em>7</em></th>
<th style="text-align: right"><em>2</em></th>
<th style="text-align: right"><em>1</em></th>
</tr>
</thead><tbody>
<tr>
<td><strong>Y</strong></td>
<td style="text-align: center"><em><strong>1</strong></em></td>
<td style="text-align: right"><em><strong>4</strong></em></td>
<td style="text-align: right"><em><strong>8</strong></em></td>
<td style="text-align: right"><em><strong>7</strong></em></td>
<td style="text-align: right"><em><strong>1</strong></em></td>
<td style="text-align: right"><em><strong>3</strong></em></td>
</tr>
</tbody></table>

<p>Repeat the same process as it was done for one dimensional data set by considering <em>X</em> and <em>Y</em> separate.
We will yield the following result,</p>

<p>Mean of X,      \(\bar{X}\) = 3.3335</p>

<p>Mean of Y,      \(\bar{Y}\) = 4.0</p>

<p>Variance of X,      \(X_{var}\) = 5.0667</p>

<p>Variance of Y,      \(Y_{var}\) = 8.8</p>

<p>Now we will introduce another parameter that will give the relation between the two dimensions. <strong>Covariance</strong>.</p>

<p>Covariance can be understood as variance but between two parameters and not by itself. Hence defined as</p>

<p><img src="/assets/images/pca/2.png" alt=""></p>

<p>If you observe covariance and variance formula we can conclude that the covariance of itself that is cov(X,X) is nothing but the variance of X. ( If you did not understand, rewrite the above formula for cov(X,X) and you will see for yourself).</p>

<p>For the above considered example the covariance is, cov(X,Y) = 5.6</p>

<p>We can represent the same in a matrix. This matrix is also called as the variance-covariance matrix.</p>

<p><img src="/assets/images/pca/1.png" alt=""></p>

<p>Note that cov(X,X) = \(X_{var}\)</p>

<p>and cov(Y,Y) = \(Y_{var}\)</p>

<p>also cov(X,Y) = cov(Y,X)</p>

<p>Thus now the variance-covariance matrix can be re-written as</p>

<p><img src="/assets/images/pca/10.png" alt=""></p>

<p>Substituting the values as calculated before we get the variance-covariance matrix for the example dataset <code>(X,Y)</code> as</p>

<p><img src="/assets/images/pca/3.png" alt=""></p>

<p>Now that we have the matrix to actually know which dataset has the most information and to extraxt the &quot;Principal&quot; information. We calculate the eigen values and eigen vectors</p>

<p>Note: In case you have forgotten how to calculate the eigen values and vectors refer <a href="https://www.scss.tcd.ie/Rozenn.Dahyot/CS1BA1/SolutionEigen.pdf">this document</a>.</p>

<p>For the example (X,Y)</p>

<p>eigen values are</p>

<p><img src="/assets/images/pca/5.png" alt=""></p>

<p>and the eigen vectors are</p>

<p><img src="/assets/images/pca/4.png" alt=""></p>

<p>The two eigen vectors obtained are perpendicular to one another.</p>

<p>Now comes the most interesting part. Read carefully, <em>&quot;The eigen vector with the highest eigen value is the principal component of the data under consideration&quot;</em>. This is what PCA is all about.</p>

<p>Here in this example the second eigen vector becomes the principal component as it has a higher eigen value of 12.83625 thus we write a feature matrix for the data set containing the eigen vectors in order of higest to lowest importance. Thus we get</p>

<p><img src="/assets/images/pca/6.png" alt=""></p>

<p>Now that we know the principal component, The last step in PCA is to get the final transformed data.</p>

<p>Let us call the final dataset as <em>Findata</em>. The above feature matrix as <em>featuremat</em></p>

<p>Consider the data set <code>(X,Y)</code></p>

<table><thead>
<tr>
<th>X</th>
<th style="text-align: center"><em>2</em></th>
<th style="text-align: right"><em>3</em></th>
<th style="text-align: right"><em>5</em></th>
<th style="text-align: right"><em>7</em></th>
<th style="text-align: right"><em>2</em></th>
<th style="text-align: right"><em>1</em></th>
</tr>
</thead><tbody>
<tr>
<td><strong>Y</strong></td>
<td style="text-align: center"><em><strong>1</strong></em></td>
<td style="text-align: right"><em><strong>4</strong></em></td>
<td style="text-align: right"><em><strong>8</strong></em></td>
<td style="text-align: right"><em><strong>7</strong></em></td>
<td style="text-align: right"><em><strong>1</strong></em></td>
<td style="text-align: right"><em><strong>3</strong></em></td>
</tr>
</tbody></table>

<p>To make the mean 0. Subtract every data in the respective datasets with its mean. (i.e. \(X-\bar{X}\) )</p>

<p>The dataset <code>(X,Y)</code> now becomes</p>

<table><thead>
<tr>
<th>X</th>
<th style="text-align: center"><em>-1.33333333</em></th>
<th style="text-align: right"><em>-0.33333333</em></th>
<th style="text-align: right"><em>1.66666667</em></th>
<th style="text-align: right"><em>3.66666667</em></th>
<th style="text-align: right"><em>-1.33333333</em></th>
<th style="text-align: right"><em>-2.33333333</em></th>
</tr>
</thead><tbody>
<tr>
<td><strong>Y</strong></td>
<td style="text-align: center"><em><strong>-3</strong></em></td>
<td style="text-align: right"><em><strong>0</strong></em></td>
<td style="text-align: right"><em><strong>4</strong></em></td>
<td style="text-align: right"><em><strong>3</strong></em></td>
<td style="text-align: right"><em><strong>-3</strong></em></td>
<td style="text-align: right"><em><strong>-1</strong></em></td>
</tr>
</tbody></table>

<p>Let us represent this in an array and call it <em>datam</em></p>

<p><img src="/assets/images/pca/7.png" alt=""></p>

<p>Let us call the final transformed dataset as <em>Findata</em>. The feature matrix as <em>featuremat</em></p>

<p>Take the transpose of <em>feauturemat</em> so that the highest eigen vector comes to the first row and the next highest to the second row and so on.</p>

<p>Now <em>featuremat</em> becomes</p>

<p><img src="/assets/images/pca/11.png" alt=""></p>

<p>We take the transpose of the <em>datam</em> if the first column contains the first dataset and second the second dataset so when transpose is taken first row will have the first dataset, second row the second dataset and so on. But in this example we have considered the <em>datam</em> itself having first row as first dataset, second row with second dataset. hence no need of transpose.</p>

<p>The very last step in PCA is</p>

<p>$$Findata = featuremat \times datam$$</p>

<p>Thus we get the final transformed data.</p>

<p>In this case <em>Findata</em> is</p>

<p><img src="/assets/images/pca/8.png" alt=""></p>

<p>This is final data obtained. To reduce a dimension that is to make this two dimensional data into one dimensional data all you have to do is consider only the highest eigen vector in the feature matrix and continue with the same steps and you will successfully reduce the data set into one dimension. The <em>Findata</em> so obtained when only the highest eigen vector is considered is</p>

<p><img src="/assets/images/pca/9.png" alt=""></p>

<p>This is what is otherwise called as data reduction or compression etc which will be discussed in detail in a separate post.</p>

<p>Now consider Multi dimensional data say <code>(A,B,C,....)</code>. Everything is same as that of two dimensional dataset. While considering eigenvectors. You can consider how many every you want based on how much reduction in data you want.</p>

<p>If you want to get the original data back from the transformed data you can read about recontruction part of PCA <a href="http://www.rajathkumar.com/pca/reconstruction">here</a></p>

<p>Now that you have understood PCA in further posts I will explain about implementing PCA in python, It&#39;s application in image compression and how it can be used for facial recognition with and without neural nets.</p>

<p>For any doubts feel free to comment or drop a mail to <em><a href="mailto:rajathkumar.exe@gmail.com">rajathkumar.exe@gmail.com</a></em> </p>

<p>Peace.</p>

        </section>
        <footer class="post-footer">
          <section class="share">
            
              
            
              
                <a class="icon-facebook" href="//www.facebook.com/sharer.php?t=Mathematically%2C+Principal+Component+Analysis&amp;u=http://www.rajathkumar.com/PCA"
                  onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
                <i class="fa fa-facebook"></i><span class="hidden">facebook</span>
                </a>
              
            
          </section>
        </footer>
        <div class="bottom-teaser cf">
          <div class="isLeft">
            <h5 class="index-headline featured"><span>Written by</span></h5>
            <section class="author">
              <div class="author-image" style="background-image: url(/assets/images/author.jpg)">Blog Logo</div>
              <h4>Rajath Kumar M.P</h4>
              <p class="bio"></p>
              <hr>
              <p class="published">Published <time datetime="2015-11-19 01:51">19 Nov 2015</time></p>
            </section>
          </div>
          
            <p><br><br><br></p>
          
          <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rajath'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
   
    
            </footer>
          </div>
        </div>
      </article>
    </main>
    <div class="bottom-closer">
      <div class="background-closer-image"  style="background-image: url(/assets/images/desktop.png)">
        Image
      </div>
      <div class="inner">
        <h1 class="blog-title">Rajath Kumar</h1>
        <h2 class="blog-description">Things that I have done, learnt and thought about.
</h2>
        <a href="/" class="btn">Back to Overview</a>
      </div>
    </div>
    <script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/assets/js/index.js"></script>
<script type="text/javascript" src="/assets/js/readingTime.min.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59670402-1', 'auto');
  ga('send', 'pageview');

</script>
<script>
(function ($) {
  "use strict";
  $(document).ready(function(){

    var $window = $(window),
    $image = $('.post-image-image, .teaserimage-image');
    $window.on('scroll', function() {
      var top = $window.scrollTop();

      if (top < 0 || top > 1500) { return; }
      $image
        .css('transform', 'translate3d(0px, '+top/3+'px, 0px)')
        .css('opacity', 1-Math.max(top/700, 0));
    });
    $window.trigger('scroll');

    var height = $('.article-image').height();
    $('.post-content').css('padding-top', height + 'px');

    $('a[href*=#]:not([href=#])').click(function() {
      if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
       && location.hostname == this.hostname) {
        var target = $(this.hash);
        target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
        if (target.length) {
          $('html,body').animate({ scrollTop: target.offset().top }, 500);
          return false;
        }
      }
    });
  });
}(jQuery));
</script>


  </body>
</html>
